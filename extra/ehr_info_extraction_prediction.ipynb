{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d1fbda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle as pkl\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.special import expit as sigmoid\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67820819",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_data = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09e729",
   "metadata": {},
   "source": [
    "## extract gender age device from CT dicoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2741e749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2884, True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(header_data, 'data.csv'))\n",
    "#data file has CT_acc (CT accessiom number), 'TOTAL_SPINE_TSCORE', 'Original DICOM file location-Axial', 'Original DICOM file location-Coronal'\n",
    "len(df), 'TOTAL_SPINE_TSCORE' in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "268c45dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (138,139,180) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "Columns (35,178,198,199,200,202) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23072, 12888)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.concat(os.path.join(header_data, 'niftis/metadata.csv'))\n",
    "mapp = pd.concat(os.path.join(header_data, 'niftis/mapping.csv'))\n",
    "len(meta), len(mapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b7fc08cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12888"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_mapped = meta.loc[meta.file.isin(mapp['Original DICOM file location'].values)]\n",
    "len(meta_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b771f96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2884\n",
      "1 0 0 0 0\n",
      "101 0 0 0 100\n",
      "201 0 0 0 200\n",
      "301 0 0 0 300\n",
      "401 0 0 0 400\n",
      "501 0 0 0 500\n",
      "601 0 0 0 600\n",
      "701 0 0 0 700\n",
      "801 0 0 0 800\n",
      "901 0 0 0 900\n",
      "1001 0 0 0 1000\n",
      "1101 0 0 0 1100\n",
      "1201 0 0 0 1200\n",
      "1301 0 0 0 1300\n",
      "1401 0 0 0 1400\n",
      "1501 0 0 0 1500\n",
      "1601 0 0 0 1600\n",
      "1701 0 0 0 1700\n",
      "1801 0 0 0 1800\n",
      "1901 0 0 0 1900\n",
      "2001 0 0 0 2000\n",
      "2101 0 0 0 2100\n",
      "2201 0 0 0 2200\n",
      "2301 0 0 0 2300\n",
      "2401 0 0 0 2400\n",
      "2501 0 0 0 2500\n",
      "2601 0 0 0 2600\n",
      "2701 0 0 0 2700\n",
      "2801 0 0 0 2800\n",
      "2884 0 0 0 2883\n"
     ]
    }
   ],
   "source": [
    "cols = [ 'Manufacturer', 'ManufacturerModelName', 'OtherPatientIDs', 'PatientAge', \n",
    "        'PatientBirthDate', 'PatientID', 'PatientSex', 'PatientSize', 'PatientWeight', \n",
    "        'ImageOrientationPatient', 'ImagePositionPatient', 'PatientPosition', \n",
    "        'PatientOrientation',  'PixelSpacing_Axial',  'PixelSpacing_Coronal']\n",
    "axial  = 0\n",
    "coronal = 0\n",
    "df[cols] = None\n",
    "for i,j in df.iterrows():\n",
    "    temp = meta_mapped.loc[(meta_mapped.AccessionNumber==df.at[i, 'CT_acc']) & (meta_mapped.file==df.at[i, 'Original DICOM file location-Transverse'])]\n",
    "    if len(temp)>0:\n",
    "        df.at[i, 'PixelSpacing_Axial'] = temp.at[temp.index[0], 'PixelSpacing']\n",
    "        axial +=1\n",
    "    else:\n",
    "        temp = meta_mapped.loc[(meta_mapped.AccessionNumber==df.at[i, 'CT_acc']) & (meta_mapped.file==df.at[i, 'Original DICOM file location-Coronal'])]\n",
    "        if len(temp)>0:\n",
    "            df.at[i, 'PixelSpacing_Coronal'] = temp.at[temp.index[0], 'PixelSpacing']\n",
    "            coronal+=1\n",
    "    if len(temp)>0:\n",
    "        for c in cols:\n",
    "            df.at[i, c] = temp.at[temp.index[0], c]\n",
    "    if i%100==0:\n",
    "        print(axial, coronal,  i)\n",
    "print(axial, coronal, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3eb7018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(header_data, 'data_w_ehr_info.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e862f026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manufacturer\t\t\t1.0\n",
      "ManufacturerModelName\t\t\t1.0\n",
      "OtherPatientIDs\t\t\t0.1252\n",
      "PatientAge\t\t\t0.932\n",
      "PatientBirthDate\t\t\t1.0\n",
      "PatientID\t\t\t1.0\n",
      "PatientSex\t\t\t1.0\n",
      "PatientSize\t\t\t0.1141\n",
      "PatientWeight\t\t\t0.1221\n",
      "ImageOrientationPatient\t\t\t1.0\n",
      "ImagePositionPatient\t\t\t1.0\n",
      "PatientPosition\t\t\t1.0\n",
      "PatientOrientation\t\t\t0.051\n"
     ]
    }
   ],
   "source": [
    "for c in cols:\n",
    "    print(c, end='\\t\\t\\t')\n",
    "    print(np.round(len(df.dropna(subset=[c]))/len(df), decimals=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98e8c1",
   "metadata": {},
   "source": [
    "### Cross Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3938e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from scipy import ndimage\n",
    "df = pd.read_csv(os.path.join(header_data, 'data_w_ehr_info.csv'))\n",
    "def vol_window(vol, level, window):\n",
    "    maxval = level + window/2\n",
    "    minval = level - window/2\n",
    "    vol[vol<minval] = minval\n",
    "    vol[vol>maxval] = maxval\n",
    "    return vol\n",
    "f = plt.figure(figsize=(16,16))\n",
    "for ii in range(0, len(df)):\n",
    "    \n",
    "    i = df.index[ii]\n",
    "    CT_acc = df.at[i, 'CT_acc']\n",
    "    slice_number = int(df.at[i, 'L3_slice'])\n",
    "\n",
    "    header = os.path.join(header_data, 'slices/axial/')\n",
    "    image_name = header+str(CT_acc)+'_'+str(slice_number)+'.npy'\n",
    "    a = np.load(image_name)\n",
    "    a = a.astype(float)\n",
    "\n",
    "    a = vol_window(a, 500, 1500)\n",
    "    a = (a-np.min(a))/(np.max(a)-np.min(a))\n",
    "    a = 255.0*a\n",
    "    mask = a.copy()\n",
    "    mask[mask>0] = 255\n",
    "    image = Image.fromarray(np.uint8(a)).convert('RGB')\n",
    "    mask_image = Image.fromarray(np.uint8(mask)).convert('RGB')\n",
    "\n",
    "    \n",
    "    labels = skimage.measure.label(mask, return_num=False)\n",
    "\n",
    "    maxCC_withbcg = labels == np.argmax(np.bincount(labels.flat))\n",
    "    maxCC_nobcg = labels == np.argmax(np.bincount(labels.flat, weights=mask.flat))\n",
    "    largest = maxCC_nobcg.copy()\n",
    "    largest[largest==False] = 0\n",
    "    largest[largest==True] = 1\n",
    "    \n",
    "    largest_filled = ndimage.binary_fill_holes(largest).astype(int)\n",
    "    max_width = max([len([i for i in range(512) if largest_filled[i, y]>0]) for y in range(512)])\n",
    "    max_depth = max([len([i for i in range(512) if largest_filled[y,i]>0]) for y in range(512)])\n",
    "    \n",
    "    #print(max_width, max_depth)\n",
    "    df.at[i, 'Width'] = max_width\n",
    "    df.at[i, 'Depth'] = max_depth\n",
    "\n",
    "    if ii % 100==0:\n",
    "        print(ii)\n",
    "\n",
    "df['CrossSection'] = np.sqrt(df['Width']*df['Depth'])\n",
    "\n",
    "def pixelspacing_0(x):\n",
    "    return float(x.split(',')[0][2:-1])\n",
    "def pixelspacing_1(x):\n",
    "    return float(x.split(',')[1][2:-2])\n",
    "df['PixelSpacing_Transverse_0'] = df.PixelSpacing_Transverse.apply(pixelspacing_0)\n",
    "df['PixelSpacing_Transverse_1'] = df.PixelSpacing_Transverse.apply(pixelspacing_1)\n",
    "a = df['PixelSpacing_Transverse_1'] == df['PixelSpacing_Transverse_0']\n",
    "\n",
    "df['WidthSpacing'] = df['Width']*df['PixelSpacing_Transverse_1']\n",
    "df['DepthSpacing'] = df['Depth']*df['PixelSpacing_Transverse_0']\n",
    "a = df['WidthSpacing']*df['DepthSpacing']\n",
    "df['CrossSectionSpacing'] = np.sqrt(a)\n",
    "\n",
    "df.to_csv(os.path.join(header_data, 'data_w_ehr_info.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4f30f",
   "metadata": {},
   "source": [
    "### Implants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2379f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def vol_window(vol, level, window):\n",
    "    maxval = level + window/2\n",
    "    minval = level - window/2\n",
    "    vol[vol<minval] = minval\n",
    "    vol[vol>maxval] = maxval\n",
    "    return vol\n",
    "df = pd.read_csv(os.path.join(header_data, 'data_w_ehr_info.csv'))\n",
    "\n",
    "for index in range(0, len(df)):\n",
    "    header = os.path.join(header_data, 'slices/axial/')\n",
    "    y = df.at[df.index[index], 'TOTAL_SPINE_TSCORE']\n",
    "\n",
    "    CT_acc = df.at[df.index[index], 'CT_acc']\n",
    "    slice_number = int(df.at[df.index[index], 'L3_slice'])\n",
    "\n",
    "    image_name = header+str(CT_acc)+'_'+str(slice_number)+'.npy'\n",
    "    a = np.load(image_name)\n",
    "    a = a.astype(float)\n",
    "    bins = [-1024, 1500, 2500, 5000]\n",
    "    hist, bin_edges = np.histogram(a, bins = bins)\n",
    "    df.at[df.index[index], '-1024_1500'] = hist[0]\n",
    "    df.at[df.index[index], '1500_2500'] = hist[1]\n",
    "    df.at[df.index[index], '2500_5000'] = hist[2]\n",
    "    if hist[1]>250 and hist[2]>250:\n",
    "        df.at[df.index[index], 'Implant'] = True\n",
    "    else:\n",
    "        df.at[df.index[index], 'Implant'] = False\n",
    "    if index%100==0:\n",
    "        print(index)\n",
    "df.to_csv(os.path.join(header_data, 'data_w_ehr_info.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec3994",
   "metadata": {},
   "source": [
    "### MRN (Patient ID) based split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8d6e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl \n",
    "mrn = list(df.MRN.values)\n",
    "mrn_train = np.random.choice(MRN, round(0.8*len(mrn)), replace=False)\n",
    "mrn_test = [i for i in mrn if i not in mrn_train]\n",
    "mrn_val = np.random.choice(mrn_train, round(0.1*len(mrn_train)), replace=False)\n",
    "MRN_train = [i for i in mrn_train if i not in mrn_val]\n",
    "\n",
    "\n",
    "dct = {'mrn_train':mrn_train, 'mrn_test': mrn_test, 'mrn_val': mrn_val}\n",
    "pkl.dump(dct, open(os.path.join(header_data, 'mrn_split.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559fc988",
   "metadata": {},
   "source": [
    "## Baseline Model, Age and Gender + Effective Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52cb96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d28ff3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6083\n",
      "6083\n",
      "0    3108\n",
      "1    2975\n",
      "Name: Label, dtype: int64\n",
      "6          2385\n",
      "7          1482\n",
      "5          1384\n",
      "8           555\n",
      "UNKNOWN     222\n",
      "9            55\n",
      "Name: PatientAge_mapped, dtype: int64\n",
      "0    2209\n",
      "1    2199\n",
      "Name: Label, dtype: int64\n",
      "0    670\n",
      "1    535\n",
      "Name: Label, dtype: int64\n",
      "1    241\n",
      "0    229\n",
      "Name: Label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (18,22) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "def labeling(x):\n",
    "    if x<=-1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def age_mapping(x):\n",
    "    if type(x) is str and len(x)==4:\n",
    "        return x[1]\n",
    "    elif type(x) is str and len(x)==3:\n",
    "        return x[0]\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "#136.1302176492294, 462.9853871884079\n",
    "df = pd.read_csv(os.path.join(header_data, 'data_w_ehr_info.csv'))\n",
    "print(len(df))\n",
    "df = df.dropna(subset=['Original DICOM file location-Axial', 'Original DICOM file location-Coronal', 'TOTAL_SPINE_TSCORE', 'L3_slice'], how='any')\n",
    "print(len(df))\n",
    "\n",
    "df['Label'] = df['TOTAL_SPINE_TSCORE'].apply(labeling)\n",
    "print(df['Label'].value_counts())\n",
    "\n",
    "df['PatientAge_mapped'] = df.PatientAge.apply(age_mapping)\n",
    "print(df['PatientAge_mapped'].value_counts())\n",
    "\n",
    "\n",
    "df['CrossSectionSpacing_binned'] = pd.cut(df['CrossSectionSpacing'].values, 10)\n",
    "\n",
    "a = df['CrossSectionSpacing'].values\n",
    "df['CrossSectionSpacing_norm'] = (a-np.min(a))/(np.max(a)-np.min(a))\n",
    "\n",
    "\n",
    "\n",
    "dct = pkl.load(open(os.path.join(header_data, 'mrn_split'), 'rb'))\n",
    "mrn_train = dct['mrn_train']\n",
    "mrn_test = dct['mrn_test']\n",
    "mrn_val = dct['mrn_val']\n",
    "\n",
    "df_train = df.loc[df.mrn.isin(mrn_train)]\n",
    "df_test = df.loc[df.mrn.isin(mrn_test)]\n",
    "df_val = df.loc[df.mrn.isin(mrn_val)]\n",
    "\n",
    "print(df_train['Label'].value_counts())\n",
    "print(df_test['Label'].value_counts())\n",
    "print(df_val['Label'].value_counts())\n",
    "\n",
    "labels_train = df_train.Label.values\n",
    "labels_test = df_test.Label.values\n",
    "labels_val = df_val.Label.values\n",
    "\n",
    "female_idx = np.array([i for i in range(len(df_test)) if df_test.PatientSex.values[i]=='F'])\n",
    "male_idx = np.array([i for i in range(len(df_test)) if df_test.PatientSex.values[i]=='M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9051fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4408, 18) (1205, 18)\n",
      "(4408, 17) (1205, 17)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       670\n",
      "           1       0.63      0.65      0.64       535\n",
      "\n",
      "    accuracy                           0.68      1205\n",
      "   macro avg       0.67      0.67      0.67      1205\n",
      "weighted avg       0.68      0.68      0.68      1205\n",
      "\n",
      "AUC-ROC:\t 0.7059045892035152\n",
      "Confusion Matrix:\n",
      " [[464 206]\n",
      " [185 350]]\n"
     ]
    }
   ],
   "source": [
    "discrete_cols = ['PatientAge_mapped', 'PatientSex', 'CrossSectionSpacing_binned']\n",
    "\n",
    "npd_discrete = df_train[discrete_cols].copy().to_numpy()\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(npd_discrete)\n",
    "\n",
    "\n",
    "mat = enc.transform(npd_discrete).todense()\n",
    "\n",
    "npd_discrete = df_test[discrete_cols].copy().to_numpy()\n",
    "\n",
    "\n",
    "mat_test = enc.transform(npd_discrete).todense() \n",
    "\n",
    "print(mat.shape, mat_test.shape)\n",
    "\n",
    "mat = np.concatenate((mat[:, :5], mat[:, 6:]), axis=1)\n",
    "mat_test = np.concatenate((mat_test[:, :5], mat_test[:, 6:]), axis=1)\n",
    "print(mat.shape, mat_test.shape)\n",
    "\n",
    "clf = MLPClassifier(random_state=0)\n",
    "clf.fit(mat, labels_train)\n",
    "pkl.dump(clf, open(os.path.join('Models/EHR/model.sav'), 'wb'))\n",
    "##########################\n",
    "preds = clf.predict(mat)\n",
    "probs = clf.predict_proba(mat)\n",
    "dct = {}\n",
    "dct['labels'] = labels_train\n",
    "dct['preds'] = preds\n",
    "dct['probs'] = probs\n",
    "pkl.dump(dct, open(os.path.join('Models/EHR/train_predictions.pkl'), 'wb'))\n",
    "#######################\n",
    "preds = clf.predict(mat_test)\n",
    "probs = clf.predict_proba(mat_test)\n",
    "\n",
    "print(classification_report(labels_test, preds))\n",
    "print('AUC-ROC:\\t', roc_auc_score(labels_test, probs[:,1]))\n",
    "cm = confusion_matrix(labels_test, preds, labels = [0, 1])\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "dct = {}\n",
    "dct['labels'] = labels_test\n",
    "dct['preds'] = preds\n",
    "dct['probs'] = probs\n",
    "pkl.dump(dct, open(os.path.join('Models/EHR/test_predictions.pkl'), 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d08305",
   "metadata": {},
   "source": [
    "shap_values[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffa6b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEMALE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.55       359\n",
      "           1       0.64      0.76      0.70       426\n",
      "\n",
      "    accuracy                           0.64       785\n",
      "   macro avg       0.64      0.63      0.62       785\n",
      "weighted avg       0.64      0.64      0.63       785\n",
      "\n",
      "AUC-ROC:\t 0.6561000170007978\n",
      "Confusion Matrix:\n",
      " [[175 184]\n",
      " [101 325]]\n",
      "MALE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.85       311\n",
      "           1       0.53      0.23      0.32       109\n",
      "\n",
      "    accuracy                           0.75       420\n",
      "   macro avg       0.65      0.58      0.58       420\n",
      "weighted avg       0.71      0.75      0.71       420\n",
      "\n",
      "AUC-ROC:\t 0.5934835835865366\n",
      "Confusion Matrix:\n",
      " [[289  22]\n",
      " [ 84  25]]\n"
     ]
    }
   ],
   "source": [
    "for gender in ['F', 'M']:\n",
    "    print(gender)\n",
    "    gender_idx = np.array([i for i in range(len(df_test)) if df_test.PatientSex.values[i]==gender])\n",
    "    print(classification_report(labels_test[gender_idx], preds[gender_idx]))\n",
    "    print('AUC-ROC:\\t', roc_auc_score(labels_test[gender_idx], probs[gender_idx,1]))\n",
    "    cm = confusion_matrix(labels_test[gender_idx], preds[gender_idx], labels = [0, 1])\n",
    "    print('Confusion Matrix:\\n', cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4de8ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74        85\n",
      "           1       0.69      0.63      0.66        70\n",
      "\n",
      "    accuracy                           0.70       155\n",
      "   macro avg       0.70      0.70      0.70       155\n",
      "weighted avg       0.70      0.70      0.70       155\n",
      "\n",
      "AUC-ROC:\t 0.7653781512605042\n",
      "Confusion Matrix:\n",
      " [[65 20]\n",
      " [26 44]]\n",
      "SIEMENS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.69       561\n",
      "           1       0.62      0.66      0.64       442\n",
      "\n",
      "    accuracy                           0.67      1003\n",
      "   macro avg       0.67      0.67      0.67      1003\n",
      "weighted avg       0.67      0.67      0.67      1003\n",
      "\n",
      "AUC-ROC:\t 0.6964797025350659\n",
      "Confusion Matrix:\n",
      " [[379 182]\n",
      " [151 291]]\n",
      "TOSHIBA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77        24\n",
      "           1       0.79      0.65      0.71        23\n",
      "\n",
      "    accuracy                           0.74        47\n",
      "   macro avg       0.75      0.74      0.74        47\n",
      "weighted avg       0.75      0.74      0.74        47\n",
      "\n",
      "AUC-ROC:\t 0.7391304347826086\n",
      "Confusion Matrix:\n",
      " [[20  4]\n",
      " [ 8 15]]\n"
     ]
    }
   ],
   "source": [
    "companies = ['ge', 'siemens', 'toshiba']\n",
    "for c in companies:\n",
    "    print(c.upper())\n",
    "    idx = np.array([i for i in range(len(df_test)) if c in df_test.Manufacturer.values[i].lower()])\n",
    "    #print(idx)\n",
    "    print(classification_report(labels_test[idx], preds[idx]))\n",
    "    print('AUC-ROC:\\t', roc_auc_score(labels_test[idx], probs[idx,1]))\n",
    "    cm = confusion_matrix(labels_test[idx], preds[idx], labels = [0, 1])\n",
    "    print('Confusion Matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fa87e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.10        56\n",
      "           1       0.70      1.00      0.82       123\n",
      "\n",
      "    accuracy                           0.70       179\n",
      "   macro avg       0.85      0.53      0.46       179\n",
      "weighted avg       0.79      0.70      0.60       179\n",
      "\n",
      "AUC-ROC:\t 0.5643873403019745\n",
      "Confusion Matrix:\n",
      " [[  3  53]\n",
      " [  0 123]]\n",
      "250-350\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       472\n",
      "           1       0.60      0.60      0.60       380\n",
      "\n",
      "    accuracy                           0.64       852\n",
      "   macro avg       0.64      0.64      0.64       852\n",
      "weighted avg       0.64      0.64      0.64       852\n",
      "\n",
      "AUC-ROC:\t 0.6552157671721678\n",
      "Confusion Matrix:\n",
      " [[319 153]\n",
      " [153 227]]\n",
      "350-1000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       142\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       174\n",
      "   macro avg       0.41      0.50      0.45       174\n",
      "weighted avg       0.67      0.82      0.73       174\n",
      "\n",
      "AUC-ROC:\t 0.5534771126760564\n",
      "Confusion Matrix:\n",
      " [[142   0]\n",
      " [ 32   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "dia = [0, 250, 350, 1000]\n",
    "for i in range(1, len(dia)):\n",
    "    lower = dia[i-1]\n",
    "    upper = dia[i]\n",
    "    print(str(lower)+'-'+str(upper))\n",
    "    idx = np.array([i for i in range(len(df_test)) if (df_test.CrossSectionSpacing.values[i]>=lower and df_test.CrossSectionSpacing.values[i]<upper)])\n",
    "    #print(idx)\n",
    "    print(classification_report(labels_test[idx], preds[idx]))\n",
    "    print('AUC-ROC:\\t', roc_auc_score(labels_test[idx], probs[idx,1]))\n",
    "    cm = confusion_matrix(labels_test[idx], preds[idx], labels = [0, 1])\n",
    "    print('Confusion Matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29d9b0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:\t0\n",
      "Iteration:\t100\n",
      "Iteration:\t200\n",
      "Iteration:\t300\n",
      "Iteration:\t400\n",
      "Iteration:\t500\n",
      "Iteration:\t600\n",
      "Iteration:\t700\n",
      "Iteration:\t800\n",
      "Iteration:\t900\n",
      "95.0 confidence interval \n",
      "Precision\n",
      "[65.5-69.1]\n",
      "Recall\n",
      "[65.6-69.2]\n",
      "F-score\n",
      "[65.5-69.1]\n",
      "AUC-ROC\n",
      "[68.6-72.6]\n"
     ]
    }
   ],
   "source": [
    "##confidence interval\n",
    "from random import randint, sample\n",
    "\n",
    "\n",
    "dct = pkl.load(open(os.path.join('Models/ehr_test_predictions.pkl'), 'rb'))\n",
    "y_test = dct['labels']\n",
    "preds = dct['preds']\n",
    "probs = dct['probs']\n",
    "\n",
    "\n",
    "target_test = y_test\n",
    "\n",
    "avg_precision = []\n",
    "avg_recall = []\n",
    "avg_fscore = []\n",
    "aucroc = []\n",
    "   \n",
    "test_set_size = len(target_test)\n",
    "for i in range(1000):\n",
    "    # randomly pick size of the test set\n",
    "    i_size = randint(round(0.5*test_set_size), test_set_size)\n",
    "    \n",
    "    i_test_idx = sample([ii for ii in range(test_set_size)], i_size)\n",
    "    i_test_idx.sort()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    i_y_test = target_test[i_test_idx]\n",
    "    i_y_pred = preds[i_test_idx]\n",
    "    i_y_prob = probs[i_test_idx,1]\n",
    "\n",
    "    dct = classification_report(i_y_test, i_y_pred, output_dict=True, zero_division=0)\n",
    "    avg_precision.append(dct['macro avg']['precision'])\n",
    "    avg_recall.append(dct['macro avg']['recall'])\n",
    "    avg_fscore.append(dct['macro avg']['f1-score'])\n",
    "\n",
    "    aucroc.append(roc_auc_score(i_y_test, i_y_prob))\n",
    "    if i%100==0:\n",
    "        print('Iteration:\\t'+str(i))\n",
    "        \n",
    "# confidence intervals\n",
    "alpha = 0.95\n",
    "print('%.1f confidence interval ' % (alpha*100))\n",
    "\n",
    "\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = np.percentile(avg_precision, p, axis= 0)\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = np.percentile(avg_precision, p, axis = 0)\n",
    "print('Precision')\n",
    "print('['+str(np.round(lower*100, decimals=1))+'-'+str(np.round(upper*100, decimals=1))+']')\n",
    "\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = np.percentile(avg_recall, p, axis= 0)\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = np.percentile(avg_recall, p, axis = 0)\n",
    "print('Recall')\n",
    "print('['+str(np.round(lower*100, decimals=1))+'-'+str(np.round(upper*100, decimals=1))+']')\n",
    "\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = np.percentile(avg_fscore, p, axis= 0)\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = np.percentile(avg_fscore, p, axis = 0)\n",
    "print('F-score')\n",
    "print('['+str(np.round(lower*100, decimals=1))+'-'+str(np.round(upper*100, decimals=1))+']')\n",
    "\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = np.percentile(aucroc, p, axis= 0)\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = np.percentile(aucroc, p, axis = 0)\n",
    "print('AUC-ROC')\n",
    "print('['+str(np.round(lower*100, decimals=1))+'-'+str(np.round(upper*100, decimals=1))+']')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
